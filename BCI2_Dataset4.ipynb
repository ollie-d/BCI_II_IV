{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b51c27",
   "metadata": {},
   "source": [
    "# Process BCI Comp II Dataset IV\n",
    "## By Ollie D'Amico\n",
    "This is not designed to be a clean or all-encompassing notebook. It is just a quick setup for students to utilize. If this alone is submitted/used without modification, a student can expect a failing grade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e764d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import chain\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.signal import butter, sosfiltfilt, sosfreqz  \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e627b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def listFlatten(l):\n",
    "    return list(chain.from_iterable(l))\n",
    "\n",
    "def dc_correct(x):\n",
    "    # Like baseline correction except it uses entire epoch mean\n",
    "    nepochs, ntimes, nchans = x.shape\n",
    "    bl_2D = np.mean(x, axis=1)\n",
    "    bl_3D = np.transpose(np.repeat(bl_2D, ntimes).reshape(nepochs, nchans, ntimes), (0, 2, 1))\n",
    "\n",
    "    return np.subtract(x, bl_3D)\n",
    "\n",
    "def wm(x, start, end, num_points): # Modified from A2\n",
    "    # Expects x = (num_obs x num_samples x num_channels)\n",
    "    num_trials = x.shape[0]\n",
    "    w = np.round((end-start)/num_points).astype(int)\n",
    "    y = np.zeros((num_points, x.shape[-1], num_trials))\n",
    "    for i in range(0, num_points):\n",
    "        s = start + (w * i)\n",
    "        e = end   + (w * i)\n",
    "        y[i, :, :] = np.mean(x[:, s:e, :], 1).T\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e51f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mat\n",
    "path = 'C:/Users/Ollie/Downloads/sp1s_aa.mat'\n",
    "data = loadmat(path)\n",
    "\n",
    "# Extract relevant pieces of data (y_test is from the website)\n",
    "clab = data['clab']\n",
    "x_train = data['x_train']\n",
    "y_train = data['y_train'].reshape(-1,)\n",
    "x_test = data['x_test']\n",
    "y_test = np.array([1,0,0,0,1,0,0,0,1,1,1,0,0,1,1,0,0,0,0,0,0,0,0,1,0,1,1,1,0,1,0,0,1,1,0,0,1,0,1,1,1,1,0,0,0,1,0,0,1,1,1,1,1,0,1,1,1,1,0,1,1,1,0,1,0,0,1,0,0,1,0,1,1,0,0,0,0,0,1,1,0,1,0,1,1,1,0,1,0,1,1,0,1,0,1,1,0,1,1,0])\n",
    "\n",
    "# Extract channels into a flattened list\n",
    "chans = np.array(listFlatten(clab[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ced05b3",
   "metadata": {},
   "source": [
    "Generate average ERPs to make sure our data are loaded in and being processed somewhat correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c1f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate C3 for plot\n",
    "ch = np.where(chans == 'C3')[0][0] \n",
    "\n",
    "# right hand movements are y_train == 1\n",
    "x_train_C3_R = x_train[:, ch, np.where(y_train == 1)]\n",
    "x_train_C3_L = x_train[:, ch, np.where(y_train == 0)]\n",
    "\n",
    "# Compute averages\n",
    "avg_C3_R = np.mean(x_train_C3_R, 2)\n",
    "avg_C3_L = np.mean(x_train_C3_L, 2)\n",
    "\n",
    "# Plot (right hand plot should look similar to paper's plot)\n",
    "fs = 100 # Hz\n",
    "dt = 1000./100 # msec\n",
    "times = np.arange(-120-500, -120, dt)\n",
    "plt.plot(times, avg_C3_R);\n",
    "plt.plot(times, avg_C3_L);\n",
    "plt.ylim([-25, 20]);\n",
    "plt.xlabel('Time (ms)');\n",
    "plt.ylabel('Amplitude at C3 ($\\mu$V)');\n",
    "plt.title('Average ERPs of Right and Left Hand Movement');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8511569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "sdt = np.round(dt).astype(int); # rounded dt so that we can index samples\n",
    "n_points = 3\n",
    "win_e = -130\n",
    "win_s = win_e - 210\n",
    "\n",
    "# Index-space window start and end\n",
    "w_s = np.where(times == win_s)[0][0]\n",
    "w_e = np.where(times == win_e)[0][0]\n",
    "\n",
    "# Transpose data for the wm function defined above\n",
    "x_train_ = np.transpose(x_train, (2, 0, 1)) # for WM\n",
    "x_test_ = np.transpose(x_test, (2, 0, 1)) # for WM\n",
    "\n",
    "# Filter the data\n",
    "fs = 100.0                                         \n",
    "lp = 5.                       \n",
    "order = 2                       \n",
    "\n",
    "# Create our filter coefficient as as a second-order section\n",
    "# Note: by defining 'fs' we don't divide our windows by the Nyquist\n",
    "sos = butter(order, lp, analog = False, btype = 'low', output = 'sos', fs = fs)\n",
    "\n",
    "# Apply 5 Hz lowpass\n",
    "x_train_ = sosfiltfilt(sos, x_train_, axis= 1)\n",
    "x_test_ = sosfiltfilt(sos, x_test_, axis= 1)\n",
    "\n",
    "# Remove DC offset from each epoch\n",
    "x_train_ = dc_correct(x_train_)\n",
    "x_test_ = dc_correct(x_test_)\n",
    "\n",
    "# Compute windowed means and flatten for sklearn\n",
    "x_train_wm = wm(x_train_, w_s, w_e, n_points)\n",
    "x_train_wm_ = x_train_wm.reshape(-1, len(chans)*n_points) \n",
    "\n",
    "x_test_wm = wm(x_test_, w_s, w_e, n_points)\n",
    "x_test_wm_ = x_test_wm.reshape(-1, len(chans)*n_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affb315a",
   "metadata": {},
   "source": [
    "Let's do some simple ML from A2\n",
    "\n",
    "**Note:** You should plot the ROC/AUC on the training data. If you don't you will not score well on your final project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b118427",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lsqrs = LinearDiscriminantAnalysis(solver = 'lsqr',  shrinkage = 'auto')\n",
    "score_lsqrs = cross_val_score(clf_lsqrs.fit(x_train_wm_, y_train), x_train_wm_, y_train, cv = 5)\n",
    "print(f'Cross val performance: {np.mean(score_lsqrs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d9c2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting just to get a rough idea of our classifier's performance\n",
    "clf_lsqrs.score(x_train_wm_, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df34c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf_lsqrs.fit(x_train_wm_, y_train)\n",
    "clf.score(x_test_wm_, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
